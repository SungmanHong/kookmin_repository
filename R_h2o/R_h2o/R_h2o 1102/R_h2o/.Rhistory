## 장애인
disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
## W_1, W_6, W_14 제거
disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")]
disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")]
disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")]
#write.table(disabled_26, 'disabled_26.csv')
#write.table(disabled_36, 'disabled_36.csv')
#write.table(disabled_46, 'disabled_46.csv')
## 신혼부부
married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM'))
## W_1, W_6, W_14 제거
married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")]
write.table(married_46, 'married_46.csv')
## 일반공급
general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
## W_1, W_6, W_14 제거
general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")]
general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")]
general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")]
#write.table(general_26, 'general_26.csv')
#write.table(general_26, 'general_36.csv')
#write.table(general_26, 'general_46.csv')
library(h2o)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM
h2o.removeAll() ## clean slate - just in case the cluster was already running
## data 불러오기
married_46 <- read.table('married_46.csv', header = TRUE)
head(married_46)
married_46 <- married_46[,-c(1:4)]
head(married_46)
## H2O DataFrame으로 변경
married_46 <- as.h2o(married_46)
married_46
splits <- h2o.splitFrame(married_46, c(0.6, 0.2), seed = 1234)
train <- h2o.assign(splits[[1]], "train.hex") # 60%
valid <- h2o.assign(splits[[2]], "valid.hex") # 60%
test <- h2o.assign(splits[[3]], "test.hex") # 60%
## 예측하고자 하는 변수지정
response = 'W_4' # 당첨/탈락 여부 필드
## predictors 지정
predictors <- setdiff(names(married_46), response)
predictors
## 모델 생성(deeplearning) 및 예측 #############################################################################################
m1 <- h2o.deeplearning(
model_id = "dl_model_first",
training_frame = train,
validation_frame = valid, ## validation dataset: used for scoring and early stopping
x = predictors,
y = response,
#activation="Rectifier",  ## default
#hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each
epochs = 1,
variable_importances = T ## not enabled by default
)
## 모델 확인
summary(m1)
pred <- h2o.predict(m1, test)
pred
## 정확도
test$Accuracy <- pred$predict == test$W_4
## 에러
1 - mean(test$Accuracy)
rf1 <- h2o.randomForest(## h2o.randomForest function
training_frame = train, ## the H2O frame for training
validation_frame = valid, ## the H2O frame for validation (not required)
x = predictors, ## the predictor columns, by column index
y = response, ## the target index (what we are predicting)
model_id = "rf_covType_v1", ## name the model in H2O
##   not required, but helps use Flow
ntrees = 200, ## use a maximum of 200 trees to create the
##  random forest model. The default is 50.
##  I have increased it because I will let
##  the early stopping criteria decide when
##  the random forest is sufficiently accurate
stopping_rounds = 2, ## Stop fitting new trees when the 2-tree
##  average is within 0.001 (default) of
##  the prior two 2-tree averages.
##  Can be thought of as a convergence setting
score_each_iteration = T, ## Predict against training and validation for
##  each tree. Default will skip several.
seed = 1000000) ## Set the random seed so that this can be
##  reproduce
summary(rf1)
finalRf_predictions <- h2o.predict(
object = rf1
, newdata = test)
finalRf_predictions
mean(finalRf_predictions$predict == test$W_4) ##1?? 왜 1인지 test set accuracy
test$Accuracy <- finalRf_predictions$predict == test$W_4
1 - mean(test$Accuracy)
gbm1 <- h2o.gbm(
training_frame = train, ## the H2O frame for training
validation_frame = valid, ## the H2O frame for validation (not required)
x = predictors, ## the predictor columns, by column index
y = response, ## the target index (what we are predicting)
model_id = "gbm_covType1", ## name the model in H2O
seed = 2000000) ## Set the random seed for reproducability
summary(gbm1)
#install.packages("stringr")
#install.packages("dplyr")
library(stringr)
library(dplyr)
full_data <- read.csv('full_data1014.csv', encoding = 'EUC-KR')
head(full_data)
## 우선/일반 나누기
full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') )
full_data.general <- full_data %>% filter(!str_detect(W_14, "우"))
## REGNUM_BLOCK 필드
full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK)
full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK)
## BLOCK_NM 필드
full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM)
full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM)
## W_3 필드
full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3)
full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3)
full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3)
full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3)
full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3)
full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3)
## W_4 필드
full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4)
full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4)
full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4)
full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4)
full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4)
full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4)
## W_13 필드
full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13)
full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13)
full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13)
full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13)
full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13)
full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13)
## W_14 필드
unique(full_data.general$W_14)
unique(full_data.priorty$W_14)
full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14)
full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14)
full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14)
full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14)
full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14)
full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14)
full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14)
full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14)
full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14)
full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14)
full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14)
full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14)
full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14)
full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14)
full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14)
full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14)
full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14)
full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14)
full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14)
full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14)
## W_15
full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15)
full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15)
full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15)
full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15)
full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15)
full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15)
full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15)
full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15)
full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15)
## W_16
## W_18
full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18)
full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18)
full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18)
full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18)
## W_27
full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27)
full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27)
full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27)
full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27)
full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27)
full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27)
full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27)
full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27)
full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27)
full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27)
full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27)
full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27)
full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27)
full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27)
full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27)
full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27)
full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27)
full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27)
full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27)
full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27)
full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27)
full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27)
full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27)
full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27)
full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27)
full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27)
full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27)
full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27)
full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27)
full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27)
full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27)
full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27)
full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27)
full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27)
full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27)
full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27)
full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27)
full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27)
full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27)
full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27)
full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27)
full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27)
full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27)
full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27)
full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27)
full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27)
## W_38
full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38)
full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38)
full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38)
full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38)
full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38)
full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38)
full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38)
full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38)
full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38)
## W_39
full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39)
full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39)
full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39)
full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39)
full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39)
full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39)
## W_40
full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40)
full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40)
full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40)
full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40)
full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40)
full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40)
summary(full_data.priorty)
summary(full_data.general)
highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH'))
highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH'))
highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH'))
## W_1, W_6, W_14 제거
highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")]
highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")]
highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")]
#write.table(highage_26, 'highage_26.csv')
#write.table(highage_36, 'highage_36.csv')
#write.table(highage_46, 'highage_46.csv')
## 장애인
disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND'))
## W_1, W_6, W_14 제거
disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")]
disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")]
disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")]
#write.table(disabled_26, 'disabled_26.csv')
#write.table(disabled_36, 'disabled_36.csv')
#write.table(disabled_46, 'disabled_46.csv')
## 신혼부부
married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM'))
## W_1, W_6, W_14 제거
married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")]
write.table(married_46, 'married_46.csv')
## 일반공급
general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC'))
## W_1, W_6, W_14 제거
general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")]
general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")]
general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")]
#write.table(general_26, 'general_26.csv')
write.table(general_36, 'general_36.csv')
#write.table(general_26, 'general_46.csv')
# rm(list = ls())
# install.packages("h2o")
library(h2o)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM
h2o.removeAll() ## clean slate - just in case the cluster was already running
## data 불러오기
general_36 <- read.table('general_36.csv', header = TRUE)
head(general_36)
general_36 <- general_36[,-c(1:4)]
head(general_36)
## H2O DataFrame으로 변경
general_36 <- as.h2o(general_36)
general_36
## data 분리(train/valid/test)
splits <- h2o.splitFrame(general_36, c(0.6, 0.2), seed = 1234)
train <- h2o.assign(splits[[1]], "train.hex") # 60%
valid <- h2o.assign(splits[[2]], "valid.hex") # 60%
test <- h2o.assign(splits[[3]], "test.hex") # 60%
## 예측하고자 하는 변수지정
response = 'W_4' # 당첨/탈락 여부 필드
## predictors 지정
predictors <- setdiff(names(general_36), response)
predictors
## 모델 생성(deeplearning) 및 예측 #############################################################################################
m1 <- h2o.deeplearning(
model_id = "dl_model_first",
training_frame = train,
validation_frame = valid, ## validation dataset: used for scoring and early stopping
x = predictors,
y = response,
#activation="Rectifier",  ## default
#hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each
epochs = 1,
variable_importances = T ## not enabled by default
)
## 모델 확인
summary(m1)
## test 데이터를 통해 모델 정확도 예측
pred <- h2o.predict(m1, test)
pred
## 정확도
test$Accuracy <- pred$predict == test$W_4
## 에러
1 - mean(test$Accuracy)
#################################################################################################################################
## 모델 생성(randomforest) ######################################################################################################
rf1 <- h2o.randomForest(## h2o.randomForest function
training_frame = train, ## the H2O frame for training
validation_frame = valid, ## the H2O frame for validation (not required)
x = predictors, ## the predictor columns, by column index
y = response, ## the target index (what we are predicting)
model_id = "rf_covType_v1", ## name the model in H2O
##   not required, but helps use Flow
ntrees = 200, ## use a maximum of 200 trees to create the
##  random forest model. The default is 50.
##  I have increased it because I will let
##  the early stopping criteria decide when
##  the random forest is sufficiently accurate
stopping_rounds = 2, ## Stop fitting new trees when the 2-tree
##  average is within 0.001 (default) of
##  the prior two 2-tree averages.
##  Can be thought of as a convergence setting
score_each_iteration = T, ## Predict against training and validation for
##  each tree. Default will skip several.
seed = 1000000) ## Set the random seed so that this can be
##  reproduce
summary(rf1)
# rf1@model$validation_metrics
# h2o.hit_ratio_table(rf1, valid = T)[1, 2]
finalRf_predictions <- h2o.predict(
object = rf1
, newdata = test)
finalRf_predictions
mean(finalRf_predictions$predict == test$W_4) ##1?? 왜 1인지 test set accuracy
test$Accuracy <- finalRf_predictions$predict == test$W_4
1 - mean(test$Accuracy)
################################################################################################################################
## 모델생성(gbm) ###############################################################################################################
gbm1 <- h2o.gbm(
training_frame = train, ## the H2O frame for training
validation_frame = valid, ## the H2O frame for validation (not required)
x = predictors, ## the predictor columns, by column index
y = response, ## the target index (what we are predicting)
model_id = "gbm_covType1", ## name the model in H2O
seed = 2000000) ## Set the random seed for reproducability
summary(gbm1)
# h2o.hit_ratio_table(gbm1, valid = T)[1, 2]
finalgbm_predictions <- h2o.predict(
object = gbm1
, newdata = test)
finalgbm_predictions
mean(finalgbm_predictions$predict == test$W_4) ##1?? 왜 1인지 test set accuracy
test$Accuracy <- finalRf_predictions$predict == test$W_4
1 - mean(test$Accuracy)
################################################################################################################################
head(general_36)
general_36 <- read.table('general_36.csv', header = TRUE)
head(general_36)
# rm(list = ls())
# install.packages("h2o")
library(h2o)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM
h2o.removeAll() ## clean slate - just in case the cluster was already running
## data 불러오기
general_36 <- read.table('general_36.csv', header = TRUE)
head(general_36)
general_36 <- general_36[,-c(1:4,8)]
head(general_36)
## H2O DataFrame으로 변경
general_36 <- as.h2o(general_36)
general_36
## data 분리(train/valid/test)
splits <- h2o.splitFrame(general_36, c(0.6, 0.2), seed = 1234)
train <- h2o.assign(splits[[1]], "train.hex") # 60%
valid <- h2o.assign(splits[[2]], "valid.hex") # 60%
test <- h2o.assign(splits[[3]], "test.hex") # 60%
## 예측하고자 하는 변수지정
response = 'W_4' # 당첨/탈락 여부 필드
## predictors 지정
predictors <- setdiff(names(general_36), response)
predictors
## 모델 생성(deeplearning) 및 예측 #############################################################################################
m1 <- h2o.deeplearning(
model_id = "dl_model_first",
training_frame = train,
validation_frame = valid, ## validation dataset: used for scoring and early stopping
x = predictors,
y = response,
#activation="Rectifier",  ## default
#hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each
epochs = 1,
variable_importances = T ## not enabled by default
)
## 모델 확인
summary(m1)
rf1 <- h2o.randomForest(## h2o.randomForest function
training_frame = train, ## the H2O frame for training
validation_frame = valid, ## the H2O frame for validation (not required)
x = predictors, ## the predictor columns, by column index
y = response, ## the target index (what we are predicting)
model_id = "rf_covType_v1", ## name the model in H2O
##   not required, but helps use Flow
ntrees = 200, ## use a maximum of 200 trees to create the
##  random forest model. The default is 50.
##  I have increased it because I will let
##  the early stopping criteria decide when
##  the random forest is sufficiently accurate
stopping_rounds = 2, ## Stop fitting new trees when the 2-tree
##  average is within 0.001 (default) of
##  the prior two 2-tree averages.
##  Can be thought of as a convergence setting
score_each_iteration = T, ## Predict against training and validation for
##  each tree. Default will skip several.
seed = 1000000) ## Set the random seed so that this can be
##  reproduce
summary(rf1)
# rf1@model$validation_metrics
# h2o.hit_ratio_table(rf1, valid = T)[1, 2]
finalRf_predictions <- h2o.predict(
object = rf1
, newdata = test)
finalRf_predictions
mean(finalRf_predictions$predict == test$W_4) ##1?? 왜 1인지 test set accuracy
test$Accuracy <- finalRf_predictions$predict == test$W_4
1 - mean(test$Accuracy)
rtvs::debug_source("script.R")
library(stringr)
library(dplyr)
install.packages("stringr")
install.packages("dplyr")
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] #write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv')
 rm(list = ls())
 install.packages("h2o")
library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running ## data 불러오기 general_36 <- read.table('general_36.csv', header = TRUE) head(general_36) general_36 <- general_36[,-c(1:4,8)] head(general_36) ## H2O DataFrame으로 변경 general_36 <- as.h2o(general_36) general_36 ## data 분리(train/valid/test) splits <- h2o.splitFrame(general_36, c(0.6, 0.2), seed = 1234) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(general_36), response) predictors ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m1 <- h2o.deeplearning(   model_id = "dl_model_first",   training_frame = train,   validation_frame = valid, ## validation dataset: used for scoring and early stopping   x = predictors,   y = response,   #activation="Rectifier",  ## default   #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each   epochs = 1,   variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m1) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m1, test) pred ## 정확도 test$Accuracy <- pred$predict == test$W_4 ## 에러 1 - mean(test$Accuracy)
library(h2o) summary(m1)localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running ## data 불러오기 general_36 <- read.table('general_36.csv', header = TRUE) head(general_36) general_36 <- general_36[,-c(1:4,8)] head(general_36) ## H2O DataFrame으로 변경 general_36 <- as.h2o(general_36) general_36 ## data 분리(train/valid/test) splits <- h2o.splitFrame(general_36, c(0.6, 0.2), seed = 1234) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(general_36), response) predictors ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m1 <- h2o.deeplearning(   model_id = "dl_model_first",   training_frame = train,   validation_frame = valid, ## validation dataset: used for scoring and early stopping   x = predictors,   y = response,   #activation="Rectifier",  ## default   #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each   epochs = 1,   variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m1) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m1, test) pred ## 정확도 test$Accuracy <- pred$predict == test$W_4 ## 에러 1 - mean(test$Accuracy)
summary(m1)
summary(m1)rf1 <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType_v1", ## name the model in H2O                                  ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                                  ##  random forest model. The default is 50.                                  ##  I have increased it because I will let                                   ##  the early stopping criteria decide when                                  ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                  ##  average is within 0.001 (default) of                                   ##  the prior two 2-tree averages.                                  ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                  ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf1)
rf1 <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType_v1", ## name the model in H2O                                  ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                                  ##  random forest model. The default is 50.                                  ##  I have increased it because I will let                                   ##  the early stopping criteria decide when                                  ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                  ##  average is within 0.001 (default) of                                   ##  the prior two 2-tree averages.                                  ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                  ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf1)
finalRf_predictions <- h2o.predict(   object = rf1   , newdata = test) finalRf_predictions mean(finalRf_predictions$predict == test$W_4) ##1?? 왜 1인지 test set accuracy test$Accuracy <- finalRf_predictions$predict == test$W_4 1 - mean(test$Accuracy)
str(m1)
$pred
str(pred)
str(finalRF_predictions)
finalRf_predictions <- h2o.predict(   object = rf1   , newdata = test)
str(finalRf_predictions)
(finalRf_predictions)
 h2o.hit_ratio_table(rf1, valid = T)[1, 2]
 rf1@model$validation_metrics
str(rf1@model$validation_metrics)
 rf1@model$validation_metrics$AUC
 rf1@model$validation_metricsrf1@model$validation_metrics@metrics$AUC
str(rf1)
finalRf_predictions
str(fifo)
str(finalRf_predictions)
summary(m1)
library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running ## data 불러오기 general_36 <- read.table('general_36.csv', header = TRUE) head(general_36) general_36 <- general_36[,-c(1:4,8)] head(general_36) ## H2O DataFrame으로 변경 general_36 <- as.h2o(general_36) general_36 ## data 분리(train/valid/test) splits <- h2o.splitFrame(general_36, c(0.6, 0.2), seed = 1234) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(general_36), response) predictors ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m1 <- h2o.deeplearning(   model_id = "dl_model_first",   training_frame = train,   validation_frame = valid, ## validation dataset: used for scoring and early stopping   x = predictors,   y = response,   #activation="Rectifier",  ## default   #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each   epochs = 1,   variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m1)
str(m1)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') fName
fName[1]
h2oData <- read.table(fName[1], header = TRUE)
as.character(fName[1])
h2oData <- read.table(as.character(fName[1]), header = TRUE)
head(h2oData)
?for
)
rm(list = ls())
# rm(list = ls()) # install.packages("h2o") library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') as.character(fName[1]) for (i in 1:10) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1234)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio, TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     (as.character(fName[i]));perf_sum; }
rm(list = ls())
# rm(list = ls()) # install.packages("h2o") library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') #as.character(fName[1]) for (i in 1:1) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1234)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio, TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     (as.character(fName[i]));perf_sum; }
    (as.character(fName[i]));perf_sum;
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv')  perf_sum[] for (i in 1:1) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1234)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio, TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum[i] <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum[i]) <- c("deep", "rf", "gbm")     print(as.character(fName[i]+"\n"),perf_sum[i]); }
    print(as.character(fName[i]+"\n"),perf_sum[i]);
    print(as.character(fName[i]+'\n'),perf_sum[i]);
    print(as.character(fName[i]),perf_sum[i]);
    print(as.character(fName[i]));perf_sum[i]);
    print(as.character(fName[i]));perf_sum[i];
    (as.character(fName[i]));print(perf_sum);
# rm(list = ls()) # install.packages("h2o") library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') for (i in 1:5) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1234)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio, TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     (as.character(fName[i]));print(perf_sum); }
# rm(list = ls()) # install.packages("h2o") library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') for (i in 6:10) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1234)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio, TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
m_cm
rm(list = ls())
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') for (i in 4:6) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
# rm(list = ls()) # install.packages("h2o") library(data.table) library(h2o) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',  'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',  'married_46.csv') for (i in 4:6) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) for (i in 4:6) {     rm(list = ls())     localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM     h2o.removeAll() ## clean slate - just in case the cluster was already running     fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv')     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex       , newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex       , newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv') for (i in 4:6) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
m_cm_ex
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv') for (i in 7:10) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
gbm_cm_ex
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv') for (i in 7:10) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));print(perf_sum); }
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv') for (i in 7:10) {     fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',          'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',          'married_46.csv')     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));
    print(perf_sum);     h2o.removeAll() }
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv',      'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv',      'married_46.csv') for (i in 7:10) {     ## data 불러오기     h2oData <- read.table(as.character(fName[1]), header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(       object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(as.character(fName[i]));
    print(perf_sum);     perf_sum <- 0; print(perf_sum) }
    str(splits)
fName='highage_26.csv'     ## data 불러오기     h2oData <- read.table(fName, header = TRUE)
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #     'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #     'married_46.csv') fName='highage_26.csv'     ## data 불러오기     h2oData <- read.table(fName, header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print(fName);
    print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #fName <- list('highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #     'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #     'married_46.csv')     ## data 불러오기     h2oData <- read.table('general_36.csv', header = TRUE)     #head(h2oData)     h2oData <- h2oData[, - c(1:4, 8)]     #head(h2oData)     #파생변수 제외 data: h2oData_ex     h2oData_ex <- h2oData[, c(1:25)]     #head(h2oData_ex)     ## H2O DataFrame으로 변경     h2oData <- as.h2o(h2oData)     #h2oData     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111)     train <- h2o.assign(splits[[1]], "train.hex") # 60%     valid <- h2o.assign(splits[[2]], "valid.hex") # 60%     test <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print('general_36.csv');
    print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(data.table) #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) #head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] #head(h2oData) #파생변수 제외 data: h2oData_ex h2oData_ex <- h2oData[, c(1:25)] #head(h2oData_ex) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) #h2oData ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(h2oData), response) #predictors ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train,       validation_frame = valid, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m, test)     #pred     #정확도=true/tot     m_cm <- h2o.confusionMatrix(m, test)     m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])     #m_Accuracy     #hit raio=TruePositive     m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2])     #m_hit     #AUC     m_perf <- h2o.performance(m, newdata = test)     m_AUC <- m_perf@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf <- h2o.randomForest(## h2o.randomForest function       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf)     finalRf_predictions <- h2o.predict(       object = rf       , newdata = test)     #finalRf_predictions     #정확도     rf_cm <- h2o.confusionMatrix(rf, test)     rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2])     #rf_Accuracy     #hit raio, TruePositive     rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2])     #rf_hit     #AUC     rf_perf <- h2o.performance(rf, newdata = test)     rf_AUC <- rf_perf@metrics$AUC     #rf_AUC     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm <- h2o.gbm(       training_frame = train, ## the H2O frame for training       validation_frame = valid, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm)     finalgbm_predictions <- h2o.predict(       object = gbm       , newdata = test)     #finalgbm_predictions     #정확도     gbm_cm <- h2o.confusionMatrix(gbm, test)     gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2])     #gbm_Accuracy     #hit raio, TruePositive     gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2])     #gbm_hit     #AUC     gbm_perf <- h2o.performance(gbm, newdata = test)     gbm_AUC <- gbm_perf@metrics$AUC     #gbm_AUC     ################################################################################################################################     ################################     ################################     ################################     #### 기존 data와 성능 비교 ########     ################################     ################################     ################################     ## H2O DataFrame으로 변경     h2oData_ex <- as.h2o(h2oData_ex)     #h2oData_ex     ## data 분리(train/valid/test)     splits <- h2o.splitFrame(h2oData_ex, c(0.6, 0.2), seed = 1234)     train_ex <- h2o.assign(splits[[1]], "train.hex") # 60%     valid_ex <- h2o.assign(splits[[2]], "valid.hex") # 60%     test_ex <- h2o.assign(splits[[3]], "test.hex") # 60%     ## 예측하고자 하는 변수지정     response = 'W_4' # 당첨/탈락 여부 필드     ## predictors 지정     predictors <- setdiff(names(h2oData_ex), response)     #predictors     ## 모델 생성(deeplearning) 및 예측 #############################################################################################     m_ex <- h2o.deeplearning(       model_id = "dl_model_first",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     )     ## 모델 확인     #summary(m_ex)     ## test 데이터를 통해 모델 정확도 예측     pred <- h2o.predict(m_ex, test_ex)     #pred     #정확도     m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex)     m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])     #m_Accuracy_ex     #hit raio, TruePositive     m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2])     #m_hit_ex     #AUC     m_perf_ex <- h2o.performance(m_ex, newdata = test_ex)     m_AUC_ex <- m_perf_ex@metrics$AUC     #################################################################################################################################     ## 모델 생성(randomforest) ######################################################################################################     rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_v1", ## name the model in H2O                                      ##   not required, but helps use Flow       ntrees = 200, ## use a maximum of 200 trees to create the                                      ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate       stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting       score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.       seed = 1000000) ## Set the random seed so that this can be     ##  reproduce     #summary(rf_ex)     finalRf_predictions_ex <- h2o.predict(object = rf_ex, newdata = test_ex)     #finalRf_predictions_ex     #정확도     rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex)     rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2])     #rf_Accuracy_ex     #hit raio, TruePositive     rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2])     #rf_hit_ex     #AUC     rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex)     rf_AUC_ex <- rf_perf_ex@metrics$AUC     #rf_AUC_ex     ################################################################################################################################     ## 모델생성(gbm) ###############################################################################################################     gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType1", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability     #summary(gbm_ex)     finalgbm_predictions_ex <- h2o.predict(object = gbm_ex, newdata = test_ex)     #finalgbm_predictions_ex     #정확도     gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex)     gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2])     #gbm_Accuracy_ex     #hit raio, TruePositive     gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2])     #gbm_hit_ex     #AUC     gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)     gbm_AUC_ex <- gbm_perf_ex@metrics$AUC     #gbm_AUC_ex     ################################################################################################################################     perf_sum <- data.frame(EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex), TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex), TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex), TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC))     rownames(perf_sum) <- c("deep", "rf", "gbm")     print('married_46.csv');
    print(perf_sum);
library(data.table)
library(h2o)
rm(list = ls())
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM
h2o.removeAll() ## clean slate - just in case the cluster was already running
h2oData <- read.table('married_46.csv', header = TRUE)
head(h2oData)
h2oData <- h2oData[, - c(1:4, 8)]
head(h2oData)
h2oData_ex <- h2oData[, c(1:25)]
head(h2oData_ex)
h2oData <- as.h2o(h2oData)
h2oData_ex <- as.h2o(h2oData_ex)
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60%
dim(train);dim(valid);dim(test);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData)
head(h2oData)
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test);
train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex);
response = 'W_4' # 당첨/탈락 여부 필드
predictors <- setdiff(names(train), response)
predictors_ex <- setdiff(names(train_ex), response)
predictors;predictors_ex;
?h2o.de
?h2o.deeplearning
m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m)
m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex)
pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex)
m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_ex_Accuracy;
m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2])
m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])
m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2])
m_Accuracy;m_ex_Accuracy;
m_Accuracy;m_Accuracy_ex;
m_hit <- m_cm[2, 2] / sum(m_cm[2, 1:2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[2, 1:2]) m_hit;m_hit_ex;
m_cm_ex;
m_cm;
count(test_ex$W_4=="W")
count.field(test_ex$W_4=="W")
count.fields(test_ex$W_4=="W")
sum(test[,test_ex$W_4=="W"])
test[,test_ex$W_4=="W"]
test_ex[,test_ex$W_4=="W"]
test_ex$W_4=="W"
m_cm_ex;
summary(pred_ex$pred)
m_cm_ex; summary(pred_ex$pred)
m_cm;
m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex
rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf)
rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex)
rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex
rf_hit <- rf_cm[2, 2] / sum(rf_cm[2, 1:2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[2, 1:2]) rf_hit;rf_hit_ex
rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex
gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex)
gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex
gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2]) gbm_hit;gbm_hit_ex
perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print('married_46.csv'); print(perf_sum);
print("'married_46.csv'"); print(perf_sum);
perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("'married_46.csv'"); print(perf_sum);
print("married_46");
gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[2, 1:2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[2, 1:2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC
gbm_AUC;gbm_AUC_ex
perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46"); print(perf_sum);
m_cm
m_hit <- m_cm[1, 1] / sum(m_cm[1, 1:2])
m_spec <- m_cm[1, 1] / sum(m_cm[1, 1:2])
m_spec_ex <- m_cm_ex[1, 1] / sum(m_cm_ex[1, 1:2])
m_spec;m_spec_ex
m_spec;m_spec_ex
m_cm_ex
sum(m_cm[1, 1:2])
sum(m_cm_ex[1, 1:2])
m_spec <- m_cm[1, 1] / sum(m_cm[1:2, 1]) m_spec_ex <- m_cm_ex[1, 1] / sum(m_cm_ex[1:2, 1]) m_spec;m_spec_ex
m_cm
str(m_cm)
m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex;
m_cm_ex;
summary(pred_ex$pred)
#특이도=TrueNegative=specificity=true neg/tot neg m_spec <- m_cm[1, 1] / sum(m_cm[1:2, 1]) m_spec_ex <- m_cm_ex[1, 1] / sum(m_cm_ex[1:2, 1]) m_spec;m_spec_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2])
m_spec;m_spec_ex
m_hit;m_hit_ex;
gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #특이도=TrueNegative=specificity=true neg/tot neg #m_spec <- m_cm[1, 1] / sum(m_cm[1:2, 1]) #m_spec_ex <- m_cm_ex[1, 1] / sum(m_cm_ex[1:2, 1]) #m_spec;m_spec_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46"); print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #특이도=TrueNegative=specificity=true neg/tot neg #m_spec <- m_cm[1, 1] / sum(m_cm[1:2, 1]) #m_spec_ex <- m_cm_ex[1, 1] / sum(m_cm_ex[1:2, 1]) #m_spec;m_spec_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36"); print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36"); print(perf_sum);
summary(gbm)
summary(rf)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_26"); print(perf_sum);
head(h2oData)
dim(h2oData)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36"); print(perf_sum);
dim(h2oData)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_26"); print(perf_sum);
print("highage_26" + dim(h2oData)[1]);
print("highage_26" + as.string(dim(h2oData)[1]));
print("highage_26" + as.character(dim(h2oData)[1]));
print("highage_26");print(dim(h2oData)[1]);
print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_46");print(dim(h2oData)[1]); print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_36");print(dim(h2oData)[1]); print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_46");print(dim(h2oData)[1]); print(perf_sum);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v2.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum);
summary(rf)
print(perf_sum);
summary(gbm)
head(h2oData)
summary(m);
str(m)
m$variable_importances
m$variable_importances
m@model$variable_importances
m@model$variable_importances;rf@model$variable_importances;gbm@model$variable_importances
("deep");m@model$variable_importances;("rf");rf@model$variable_importances;("gbm");gbm@model$variable_importances
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances;("rf");rf@model$variable_importances;("gbm");gbm@model$variable_importances
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances;("rf");rf@model$variable_importances;("gbm");gbm@model$variable_importances
gbm_cm_ex
gbm_cm
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
m@model$variable_importances;
rf@model$variable_importances;
gbm@model$variable_importances;
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
m@model$variable_importances;
rf@model$variable_importances;
gbm@model$variable_importances;
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
print(perf_sum);
m@model$variable_importances;
rf@model$variable_importances;
gbm@model$variable_importances;
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
m@model$variable_importances;
rf@model$variable_importances;
gbm@model$variable_importances;
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
m@model$variable_importances;
print(perf_sum);
rf@model$variable_importances;
gbm@model$variable_importances;
print(perf_sum);
rf@model$variable_importances;
#("gbm");gbm@model$variable_importances;
gbm@model$variable_importances;
m@model$variable_importances;
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData)
h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");m@model$variable_importances; #("rf");rf@model$variable_importances; #("gbm");gbm@model$variable_importances;
m@model$variable_importances;
rf@model$variable_importances;
gbm@model$variable_importances;
print(perf_sum);
head(h2oData)
head(h2oData_ex)
head(train)
head(train_ex)
m@model
tail(m@model$variable_importances,10)
head(m@model$variable_importances,100)
head(m@model$variable_importances,51)
head(m@model$variable_importances,10)
head(rf@model$variable_importances,10)
head(gbm@model$variable_importances,10)
print(perf_sum);
gbm_cm
gbm_cm_ex
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex
library(h2o)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex
m_cm
pred$predict
summary(pred$predict)
summary(test$W_4)
m_cm
summary(pred$predict)
str(pred$predict)
str(pred)
table(pred$predict)
summary(pred$predict)
sum(pred$predict=="W")
sum(pred$predict=="L")
sum(pred$predict=="L" & test$W_4== "L")
m_cm
c(pred$predict,test$W_4)
cbind(pred$predict,test$W_4)
m <- cbind(pred$predict,test$W_4)
m
m <- c(pred$predict,test$W_4)
m
summary(m)
str(m)
summary(m$predict,m$W_4)
describe(m$predict,m$W_4)
table(m$predict,m$W_4)
data.table(m$predict,m$W_4)
library(data.t)
library(data.table)
data.table(m$predict,m$W_4)
m$predict
str(m)
m[1,1]
dim(m)
m
dim(m[[1]])
m[[2]]
data.table(m[[1]],m[[2]])
m[[]]
m[[1]]
m <- c(test$W_4,pred$predict)
m
m$actual * pred <- as.character(m[[1]]) +as.character(m[[2]])
m$actual_pred <- as.character(m[[1]]) +as.character(m[[2]])
m$ac
m$actual_pred
m$actual_pred <- as.character(m[[1]]) +as.character(m[[2]])
m$actual_pred
m$actual_pred
m$actual_pred
m$actual_pred
m
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1022.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #정확도=true/tot #m <- c(test$W_4,pred$predict) #m$actual_pred <- as.character(m[[1]]) +as.character(m[[2]]) #m m_cm <- h2o.confusionMatrix(m, test) m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) m_hit;m_hit_ex; #m_cm;m_cm_ex; #summary(pred_ex$pred) #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) finalRf_predictions <- h2o.predict(   object = rf, newdata = test) finalRf_predictions_ex <- h2o.predict(   object = rf_ex, newdata = test_ex) #정확도 rf_cm <- h2o.confusionMatrix(rf, test) rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) rf_hit;rf_hit_ex #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) finalgbm_predictions <- h2o.predict(       object = gbm, newdata = test) finalgbm_predictions_ex <- h2o.predict(       object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex #정확도 gbm_cm <- h2o.confusionMatrix(gbm, test) gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) gbm_hit;gbm_hit_ex #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
dim(train);dim(valid);dim(test);
dim(train_ex);dim(valid_ex);dim(test_ex);
summary(m)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
(m_Accuracy )
rf_Accuracy
gbm_Accuracy
m_hit_ex
m_AUC
rf_AUC
gbm_perf <- h2o.performance(gbm, newdata = test)
gbm_AUC <- gbm_perf@metrics$AUC
gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex)
gbm_AUC_ex <- gbm_perf_ex@metrics$AUC
gbm_AUC;gbm_AUC_ex
pred <- h2o.predict(m, test)
pred_ex <- h2o.predict(m_ex, test_ex)
pred
matrix <- c(test$W_4,pred$predict)
matrix
cross
test
m_perf <- h2o.performance(m, newdata = test)
m_perf
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test)
m_perf
test
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(h2oData)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('full_data1023_plus3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') write.table(highage_26, 'highage_26_plus.csv') write.table(highage_36, 'highage_36_plus.csv') write.table(highage_46, 'highage_46_plus.csv') write.table(disabled_26, 'disabled_26_plus.csv') write.table(disabled_36, 'disabled_36_plus.csv') write.table(disabled_46, 'disabled_46_plus.csv') write.table(married_46, 'married_46_plus.csv') write.table(general_26, 'general_26_plus.csv') write.table(general_36, 'general_36_plus.csv') write.table(general_26, 'general_46_plus.csv')
plusData <- read.table('general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:25)]
head(plusData)
full_data <- read.csv('full_data1023_plus3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우"))
head(full_data)
full_data <- read.csv('full_data1023_plus3.csv', encoding = 'EUC-KR') head(full_data)
full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우"))
h2o.init(ip = "IP", port = 54321, startH2O = false)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('full_data1019v3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv') ###################### #write.table(highage_26, 'highage_26_plus.csv') #write.table(highage_36, 'highage_36_plus.csv') #write.table(highage_46, 'highage_46_plus.csv') #write.table(disabled_26, 'disabled_26_plus.csv') #write.table(disabled_36, 'disabled_36_plus.csv') #write.table(disabled_46, 'disabled_46_plus.csv') #write.table(married_46, 'married_46_plus.csv') #write.table(general_26, 'general_26_plus.csv') #write.table(general_36, 'general_36_plus.csv') #write.table(general_26, 'general_46_plus.csv')
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData)
 install.packages("h2o")
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
library(h2o)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
head(h2oData)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('full_data1023_plus3.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, 'highage_26_plus.csv') write.table(highage_36, 'highage_36_plus.csv') write.table(highage_46, 'highage_46_plus.csv') write.table(disabled_26, 'disabled_26_plus.csv') write.table(disabled_36, 'disabled_36_plus.csv') write.table(disabled_46, 'disabled_46_plus.csv') write.table(married_46, 'married_46_plus.csv') write.table(general_26, 'general_26_plus.csv') write.table(general_36, 'general_36_plus.csv') write.table(general_26, 'general_46_plus.csv')
plusData <- read.table('general_36_plus.csv', header = TRUE) head(plusData)
full_data.general
head(full_data)
summary(full_data.priorty)
summary(full_data.general)
highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH'))
highage_26
highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH'))
highage_36
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('full_data1023_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, 'highage_26_plus.csv') write.table(highage_36, 'highage_36_plus.csv') write.table(highage_46, 'highage_46_plus.csv') write.table(disabled_26, 'disabled_26_plus.csv') write.table(disabled_36, 'disabled_36_plus.csv') write.table(disabled_46, 'disabled_46_plus.csv') write.table(married_46, 'married_46_plus.csv') write.table(general_26, 'general_26_plus.csv') write.table(general_36, 'general_36_plus.csv') write.table(general_26, 'general_46_plus.csv')
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData)
h2oData <- as.h2o(h2oData)
plusData <- read.table('general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:25)]
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:25)] valid_ex <- valid[, c(1:25)] test_ex <- test[, c(1:25)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10);
pred_ex <- h2o.predict(m_ex, plusData_ex)
matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW))
m_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(pred_ex$predict)[1]
m_Accuracy_ex
m_hit <- cross[4]/(cross[3]+cross[4])
m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4])
m_hit_ex;
plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1]
plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4])
plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex)
##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC
plus_m_AUC_ex
plus_m_AUC_ex <- plus_perf_ex@metrics$AUC
plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex)
plus_m_AUC_ex <- plus_perf_ex@metrics$AUC
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData)
plusData <- read.table('./general_36_plus.csv', header = TRUE) head(plusData)
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE)
head(plusData)
plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:25)]
plusData_ex
plusData 
plusData_ex <- plusData[, c(1:25)]
plusData_ex
rownames(plusData)
plusData_ex <- plusData[, c(1:25)]str(plusData)
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData)
head(plusData)
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- as.h2o(plusData)
str(plusData)
plusData_ex <- plusData[, c(1:22)]
plusData_ex
h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData)
train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex);
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred ##pred <- h2o.predict(m, plusData) ##pred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) ##plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) m_hit; m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) ##plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) ##error m_AUC_ex <- m_perf_ex@metrics$AUC ##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC  ##error m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum);
pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
pluspred <- h2o.predict(m, plusData)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1023_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, 'highage_26_plus.csv') write.table(highage_36, 'highage_36_plus.csv') write.table(highage_46, 'highage_46_plus.csv') write.table(disabled_26, 'disabled_26_plus.csv') write.table(disabled_36, 'disabled_36_plus.csv') write.table(disabled_46, 'disabled_46_plus.csv') write.table(married_46, 'married_46_plus.csv') write.table(general_26, 'general_26_plus.csv') write.table(general_36, 'general_36_plus.csv') write.table(general_26, 'general_46_plus.csv')
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData)
plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData)
matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
matrix <- c(plusData$W_4, pluspred$predict)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex)
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData)
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData)
h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred ##pred <- h2o.predict(m, plusData) ##pred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) ##plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) m_hit; m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) ##plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) ##error m_AUC_ex <- m_perf_ex@metrics$AUC ##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC  ##error m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
pluspred <- h2o.predict(m, plusData)
full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1023_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex)
matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
cross
matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW))
cross_ex
plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex
plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex;
plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC
plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex
pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex)
matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW))
plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex
plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex;
plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex
pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW))
plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex
plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex;
plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex
plus_sum <- data.frame(     EX.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EX.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EX.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred ##pred <- h2o.predict(m, plusData) ##pred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) ##plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) m_hit; m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) ##plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) ##error m_AUC_ex <- m_perf_ex@metrics$AUC ##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC  ##error m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/general_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_46"); print(dim(h2oData)[1]); print(perf_sum); print("general_46_plus"); print(dim(plusData)[1]); print(plus_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred ##pred <- h2o.predict(m, plusData) ##pred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) ##plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) m_hit; m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) ##plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) ##error m_AUC_ex <- m_perf_ex@metrics$AUC ##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC  ##error m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
plusData_ex
h2oData
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1023_plusex.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred ##pred <- h2o.predict(m, plusData) ##pred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) ##plus_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) m_hit; m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) ##plus_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) ##error m_AUC_ex <- m_perf_ex@metrics$AUC ##plus_m_AUC_ex <- plus_perf_ex@metrics$AUC  ##error m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_36"); print(dim(h2oData)[1]); print(perf_sum); print("highage_36_plus"); print(dim(plusData)[1]); print(plus_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_46"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_46_plus"); print(dim(plusData)[1]); print(plus_sum);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1023_plusex.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
library(h2o)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
cross
cross_ex
install.packages("h2o")
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData)
library(h2o)
h2oData <- as.h2o(h2oData)
localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM
h2oData <- as.h2o(h2oData)
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1027_plusex.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv full_data <- read.csv('./plus/full_data1027_plusex.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ###################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
cross_ex
dim(pluspred$predict)[1]
cross[1]
dim(pluspred_ex$predict)[1]
cross_ex[1]
cross_ex[4]
cross_ex[3] + cross_ex[4]
cross_ex[3]
cross_ex[4]
plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex)
plusm_perf_ex@metrics
plusm_AUC_ex
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('full_data1022.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv') ####################### #write.table(highage_26, './plus/highage_26_plus.csv') #write.table(highage_36, './plus/highage_36_plus.csv') #write.table(highage_46, './plus/highage_46_plus.csv') #write.table(disabled_26, './plus/disabled_26_plus.csv') #write.table(disabled_36, './plus/disabled_36_plus.csv') #write.table(disabled_46, './plus/disabled_46_plus.csv') #write.table(married_46, './plus/married_46_plus.csv') #write.table(general_26, './plus/general_26_plus.csv') #write.table(general_36, './plus/general_36_plus.csv') #write.table(general_26, './plus/general_46_plus.csv')
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
##install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ####################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
print(perf_sum);
head(m@model$variable_importances,10);
################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ####################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
head(gbm@model$variable_importances,10);
head(rf@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_36"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_36_plus"); print(dim(plusData)[1]); print(plus_sum);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
head(m@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36.csv");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_36.csv_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_36.csv"); print(dim(h2oData)[1]); print(perf_sum); print("highage_36.csv_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_36"); print(dim(h2oData)[1]); print(perf_sum); print("highage_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(rf@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(plusData)
summary(plusData)
plusData$W_14
summary(married_46)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv')
summary(married_46)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14)
summary(subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM')))
length(subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM')))
dim(subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM')))
print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
head(gbm@model$variable_importances,10)
head(rf@model$variable_importances,10);
head(m@model$variable_importances,10);
matrix_ex
plusData
plusData$Actual <- plusData$W_4 plusData$pred <- pluspred plusData
plusData$Actual <- plusData$W_4
plusData
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
library(h2o)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
pluspred
plusData
plusData$perd <- pluspred
plusData
plusData$perd <- pluspred$predict
library(h2o)
# rm(list = ls()) # install.packages("h2o") #library(h2o) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData$pred <- pluspred$predict
plusData
write.csv(plusData,"plus_predict.csv")
write.table(plusData,"plus_predict.csv")
write.table(plusData,'plus_predict.csv')
?write.csv
write.table(plusData,fileEncoding = "plus_predict.csv",row.names = TRUE)
library(stringr);library(dplyr)
write.table(plusData,fileEncoding = "plus_predict.csv",row.names = TRUE)
cross
plus <- data.table(plusData)
plus <- data.frame(plusData)
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) #dim(subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM'))) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ####################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1019v3.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) #dim(subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM'))) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv') ####################### #write.table(highage_26, './plus/highage_26_plus.csv') #write.table(highage_36, './plus/highage_36_plus.csv') #write.table(highage_46, './plus/highage_46_plus.csv') #write.table(disabled_26, './plus/disabled_26_plus.csv') #write.table(disabled_36, './plus/disabled_36_plus.csv') #write.table(disabled_46, './plus/disabled_46_plus.csv') #write.table(married_46, './plus/married_46_plus.csv') #write.table(general_26, './plus/general_26_plus.csv') #write.table(general_36, './plus/general_36_plus.csv') #write.table(general_26, './plus/general_46_plus.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
head(m@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_26");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_26_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_26"); print(dim(h2oData)[1]); print(perf_sum); print("highage_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_36"); print(dim(h2oData)[1]); print(perf_sum); print("highage_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_46"); print(dim(h2oData)[1]); print(perf_sum); print("highage_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(rf@model$variable_importances,10);
head(m@model$variable_importances,10);
head(m_ex@model$variable_importances,10);
head(plusData)
plusData_ex <- plusData[, c(1:22)]
plusData_ex
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('highage_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("highage_26");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/highage_26_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("highage_26"); print(dim(h2oData)[1]); print(perf_sum); print("highage_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_26");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_26_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_26"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26,csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_26.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_26");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_26_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_26"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
summary(m_ex)
dim(train_ex);dim(valid_ex);dim(test_ex);
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) supplyNum <- read.csv('supply_num.csv', header = TRUE) h2oData <- left_join(h2oData,supplyNum,by = h2oData$BLOCK_NM)
h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM")
library(dplyr)
h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM")
head(h2oData)
dim(h2oData)
h2oData[1,44]
h2oData <- h2oData[, - c(1:4, 8,43)]
head(h2oData)
h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)]
head(plusData)
plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(gbm@model$variable_importances,10);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData)
rownames(h2oData)
colnames(h2oData)
h2oData <- h2oData[, c(7,11,24:27,38:42)]
head(h2oData)
## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") h2oData <- h2oData[, c(7,11,24:27,38:42)] #h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData)
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex);
response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response)
head(h2oData)
train_ex <- train[, c(1:6)] valid_ex <- valid[, c(1:6)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex);
test_ex <- test[, c(1:6)]
dim(train_ex);dim(valid_ex);dim(test_ex);
response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex
rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") #plusData <- plusData[, - c(1:4, 8, 43)] plusData <- plusData[, c(7, 11, 24:27, 38:42)] #plusData <- plusData[, - c(1:4, 8)] head(plusData)
plusData <- as.h2o(plusData) #plusData_ex <- plusData[, c(1:22)] plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
head(plus)
head(plusData)
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData)
supplyNum <- read.csv('supply_num.csv', header = TRUE) h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM")
head(h2oData)
colnames(h2oData)
h2oData <- h2oData[, c(7,11,24:27,38:42,44)]
head(h2oData)
h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test);
train_ex <- train[, c(1:6)] valid_ex <- valid[, c(1:6)] test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM")
head(plusData)
plusData <- plusData[, c(7, 11, 24:27, 38:42,44)]
head(plusData)
plusData <- as.h2o(plusData) #plusData_ex <- plusData[, c(1:22)] plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running
h2oData <- read.table('disabled_26.csv', header = TRUE) head(h2oData)
colnames(h2oData)
h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData)
h2oData <- as.h2o(h2oData)
splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test #train_ex <- train[, c(1:22)] #valid_ex <- valid[, c(1:22)] #test_ex <- test[, c(1:22)] train_ex <- train[, c(1:6)] valid_ex <- valid[, c(1:6)] test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_26");print(dim(h2oData)[1]); print(perf_sum);
 rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_26.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_26");print(dim(h2oData)[1]); print(perf_sum);
head(h2oData)
head(h2oData_ex)
train_ex
plusData <- read.table('./plus/disabled_26_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_26"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_36.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_36_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_36"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('disabled_46.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("disabled_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/disabled_46_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("disabled_46"); print(dim(h2oData)[1]); print(perf_sum); print("disabled_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_26.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_26");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_26_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_26"); print(dim(h2oData)[1]); print(perf_sum); print("general_26_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_46.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_46_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_46"); print(dim(h2oData)[1]); print(perf_sum); print("general_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8,43)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8, 43)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1022.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('full_data1022.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv') ####################### #write.table(highage_26, './plus/highage_26_plus.csv') #write.table(highage_36, './plus/highage_36_plus.csv') #write.table(highage_46, './plus/highage_46_plus.csv') #write.table(disabled_26, './plus/disabled_26_plus.csv') #write.table(disabled_36, './plus/disabled_36_plus.csv') #write.table(disabled_46, './plus/disabled_46_plus.csv') #write.table(married_46, './plus/married_46_plus.csv') #write.table(general_26, './plus/general_26_plus.csv') #write.table(general_36, './plus/general_36_plus.csv') #write.table(general_26, './plus/general_46_plus.csv')
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) #full_data1022.csv / ./plus/full_data1027_plusex.csv full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신')) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(highage_26, 'highage_26.csv') #write.table(highage_36, 'highage_36.csv') #write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(disabled_26, 'disabled_26.csv') #write.table(disabled_36, 'disabled_36.csv') #write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] #write.table(general_26, 'general_26.csv') #write.table(general_36, 'general_36.csv') #write.table(general_26, 'general_46.csv') ####################### write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] #train_ex <- train[, c(1:6)] #valid_ex <- valid[, c(1:6)] #test_ex <- test[, c(1:6)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex #m_cm <- h2o.confusionMatrix(m, test) #m_Accuracy <- (m_cm[1, 1] + m_cm[2, 2]) / sum(m_cm[1:2, 1:2]) #m_cm_ex <- h2o.confusionMatrix(m_ex, test_ex) #m_Accuracy_ex <- (m_cm_ex[1, 1] + m_cm_ex[2, 2]) / sum(m_cm_ex[1:2, 1:2]) #m_hit <- m_cm[2, 2] / sum(m_cm[1:2, 2]) #m_hit_ex <- m_cm_ex[2, 2] / sum(m_cm_ex[1:2, 2]) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex #정확도 #rf_cm <- h2o.confusionMatrix(rf, test) #rf_Accuracy <- (rf_cm[1, 1] + rf_cm[2, 2]) / sum(rf_cm[1:2, 1:2]) #rf_cm_ex <- h2o.confusionMatrix(rf_ex, test_ex) #rf_Accuracy_ex <- (rf_cm_ex[1, 1] + rf_cm_ex[2, 2]) / sum(rf_cm_ex[1:2, 1:2]) #rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos #rf_hit <- rf_cm[2, 2] / sum(rf_cm[1:2, 2]) #rf_hit_ex <- rf_cm_ex[2, 2] / sum(rf_cm_ex[1:2, 2]) #rf_hit;rf_hit_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex #정확도 #gbm_cm <- h2o.confusionMatrix(gbm, test) #gbm_Accuracy <- (gbm_cm[1, 1] + gbm_cm[2, 2]) / sum(gbm_cm[1:2, 1:2]) #gbm_cm_ex <- h2o.confusionMatrix(gbm_ex, test_ex) #gbm_Accuracy_ex <- (gbm_cm_ex[1, 1] + gbm_cm_ex[2, 2]) / sum(gbm_cm_ex[1:2, 1:2]) #gbm_Accuracy;gbm_Accuracy_ex #hit raio, TruePositive #gbm_hit <- gbm_cm[2, 2] / sum(gbm_cm[1:2, 2]) #gbm_hit_ex <- gbm_cm_ex[2, 2] / sum(gbm_cm_ex[1:2, 2]) #gbm_hit;gbm_hit_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) #plusData <- left_join(plusData, supplyNum, by = "BLOCK_NM") plusData <- plusData[, - c(1:4, 8)] #plusData <- plusData[, c(7, 11, 24:27, 38:42,44)] #plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] #plusData_ex <- plusData[, c(1:6)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('./plus/full_data1027_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신')) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)]
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'general_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/general_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex,newdata=plusData_ex),"f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex),thresholds=thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_46"); print(dim(h2oData)[1]); print(perf_sum); print("general_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)]
thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm,newdata=test),"f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test),thresholds=thred) h2o.tpr(h2o.performance(gbm, newdata =test), thresholds = thred)
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm,newdata=test),"f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test),thresholds=thred) h2o.tpr(h2o.performance(gbm, newdata =test), thresholds = thred) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)]
thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm,newdata=test),"f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test),thresholds=thred) h2o.tpr(h2o.performance(gbm, newdata =test), thresholds = thred)
thred=h2o.find_threshold_by_max_metric(h2o.performance(gbm,newdata=plusData),"f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.varimp(gbm)
head(data.frame(h2o.varimp(gbm)))
h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.auc(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.auc(h2o.performance(gbm, newdata = plusData))
h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred)
plusData
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred #confusion Matrix matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accuracy;m_Accuracy_ex #hit raio=TruePositive=true pos/tot pos m_hit <- cross[4]/(cross[3]+cross[4]) m_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) m_hit;m_hit_ex; #AUC m_perf <- h2o.performance(m, newdata = test) m_AUC <- m_perf@metrics$AUC m_perf_ex <- h2o.performance(m_ex, newdata = test_ex) m_AUC_ex <- m_perf_ex@metrics$AUC m_AUC;m_AUC_ex ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) matrix <- c(test$W_4,rf_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,rf_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot rf_Accuracy <- (cross[1]+cross[4])/dim(rf_pred$predict)[1] rf_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(rf_pred_ex$predict)[1] rf_Accuracy;rf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos rf_hit <- cross[4]/(cross[3]+cross[4]) rf_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) rf_hit;rf_hit_ex; #AUC rf_perf <- h2o.performance(rf, newdata = test) rf_AUC <- rf_perf@metrics$AUC rf_perf_ex <- h2o.performance(rf_ex, newdata = test_ex) rf_AUC_ex <- rf_perf_ex@metrics$AUC rf_AUC;rf_AUC_ex ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,  # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "gbm_covType_ex", ## name the model in H2O       balance_classes = T,   #    max_after_balance_size = 5,       seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex matrix <- c(test$W_4,gbm_pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW)) matrix_ex <- c(test_ex$W_4,gbm_pred_ex$predict) matrix_ex$LL <- matrix_ex[[1]]=="L" & matrix_ex[[2]]=="L" matrix_ex$LW <- matrix_ex[[1]]=="L" & matrix_ex[[2]]!="L" matrix_ex$WL <- matrix_ex[[1]]!="L" & matrix_ex[[2]]=="L" matrix_ex$WW <- matrix_ex[[1]]!="L" & matrix_ex[[2]]!="L" cross_ex <-c(sum(matrix_ex$LL),sum(matrix_ex$LW),sum(matrix_ex$WL),sum(matrix_ex$WW)) #정확도=true/tot gbm_Accuracy <- (cross[1]+cross[4])/dim(gbm_pred$predict)[1] gbm_Accuracy_ex <- (cross_ex[1]+cross_ex[4])/dim(gbm_pred_ex$predict)[1] gbm_Accuracy;gbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos gbm_hit <- cross[4]/(cross[3]+cross[4]) gbm_hit_ex <- cross_ex[4]/(cross_ex[3]+cross_ex[4]) gbm_hit;gbm_hit_ex; #AUC gbm_perf <- h2o.performance(gbm, newdata = test) gbm_AUC <- gbm_perf@metrics$AUC gbm_perf_ex <- h2o.performance(gbm_ex, newdata = test_ex) gbm_AUC_ex <- gbm_perf_ex@metrics$AUC gbm_AUC;gbm_AUC_ex perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] ##plus_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] plusm_Accuracy;plusm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusm_hit <- cross[4] / (cross[3] + cross[4]) plusm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusm_hit;plusm_hit_ex; #AUC plusm_perf <- h2o.performance(m, newdata = plusData) plusm_AUC <- plusm_perf@metrics$AUC plusm_perf_ex <- h2o.performance(m_ex, newdata = plusData_ex) plusm_AUC_ex <- plusm_perf_ex@metrics$AUC plusm_AUC;plusm_AUC_ex #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusrf_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusrf_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusrf_Accuracy;plusrf_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusrf_hit <- cross[4] / (cross[3] + cross[4]) plusrf_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusrf_hit;plusrf_hit_ex; #AUC plusrf_perf <- h2o.performance(rf, newdata = plusData) plusrf_AUC <- plusrf_perf@metrics$AUC plusrf_perf_ex <- h2o.performance(rf_ex, newdata = plusData_ex) plusrf_AUC_ex <- plusrf_perf_ex@metrics$AUC plusrf_AUC;plusrf_AUC_ex #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) #confusion Matrix matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC;plusgbm_AUC_ex plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.auc(h2o.performance(gbm, newdata = plusData))
plusData_ex
thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex))
thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex))
h2o.table(plusData_ex$W_4)
  ntrees=10000,n
checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability
gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability
h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.auc(h2o.performance(gbm, newdata = plusData))
h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred)
gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex)
checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex)
h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex))
head(data.frame(h2o.varimp(gbm)))
tmp_pred = h2o.predict(gbm, plusData)
tmp_pred
tmp_pred$W
h2o.table(tmp_pred$W)
tmp_varimp = head(data.frame(h2o.varimp(gbm)))
tmp_varimp
h2o.corr(tmp_pred$W,tmp_pred$A_47)
h2o.cor(tmp_pred$W,tmp_pred$A_47)
h2o.cor(tmp_pred$W, tmp_pred$A_47)
h2o.cor(tmp_pred$W, tmp_pred$W_28)
h2o.cor(tmp_pred$W, tmp_pred$W_29)
h2o.cor(tmp_pred$W, tmp_pred$W_20)
h2o.cor(tmp_pred$W, tmp_pred$W_38)
tmp_pred
tmp_pred
h2o.cor(tmp_pred$W, tmp_pred$A_47)
h2o.cor(tmp_pred$W, tmp_pred$W_28)
h2o.cor(tmp_pred$W, tmp_pred$W_29)
h2o.cor(tmp_pred$W, tmp_pred$W_20)
h2o.cor(tmp_pred$W, tmp_pred$W_38)
aggregate(train$A_47, by = train$W_4, FUN=mean)
aggregate(train$A_47, by = list(train$W_4), FUN=mean)
tmp_train=as.data.frame(train)
aggregate(tmp_train$A_47, by = list(tmp_train$W_4), FUN = mean)
setNames(aggregate(tmp_train$A_47, by = list(tmp_train$W_4), FUN = mean),c("Y","X"))
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred
h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred)
matrix <- c(test$W_4,pred$predict) matrix$LL <- matrix[[1]]=="L" & matrix[[2]]=="L" matrix$LW <- matrix[[1]]=="L" & matrix[[2]]!="L" matrix$WL <- matrix[[1]]!="L" & matrix[[2]]=="L" matrix$WW <- matrix[[1]]!="L" & matrix[[2]]!="L" cross <-c(sum(matrix$LL),sum(matrix$LW),sum(matrix$WL),sum(matrix$WW))
cross
h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred)
h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) h2o.auc(h2o.performance(m, newdata = test))
m_Accuracy <- (cross[1]+cross[4])/dim(pred$predict)[1] m_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pred_ex$predict)[1] m_Accurac
m_Accuracy
h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred)
m_hit <- cross[4]/(cross[3]+cross[4])
m_hit
h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex))
h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex))
rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex))
checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
m_AUC <- h2o.auc(h2o.performance(m, newdata = test))
m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex))
perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex, rf_Accuracy_ex, gbm_Accuracy_ex),     TEST.Accuracy = c(m_Accuracy, rf_Accuracy, gbm_Accuracy),     EX.HIT = c(m_hit_ex, rf_hit_ex, gbm_hit_ex),      TEST.HIT = c(m_hit, rf_hit, gbm_hit),     EX.AUC = c(m_AUC_ex, rf_AUC_ex, gbm_AUC_ex),      TEST.AUC = c(m_AUC, rf_AUC, gbm_AUC)) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
print(perf_sum);
print(perf_sum);
print(dim(h2oData)[1]);
m_Accuracy_ex
m_Accuracy_ex[[1]]
perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex)
h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex))
pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex))
pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex, plusrf_Accuracy_ex, plusgbm_Accuracy_ex),     PLUS.Accuracy = c(plusm_Accuracy, plusrf_Accuracy, plusgbm_Accuracy),     EXPLUS.HIT = c(plusm_hit_ex, plusrf_hit_ex, plusgbm_hit_ex),     PLUS.HIT = c(plusm_hit, plusrf_hit, plusgbm_hit),     EXPLUS.AUC = c(plusm_AUC_ex, plusrf_AUC_ex, plusgbm_AUC_ex),     PLUS.AUC = c(plusm_AUC, plusrf_AUC, plusgbm_AUC)) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train);dim(valid);dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex);dim(valid_ex);dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,        stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46");print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #########################plus data##################### ################# plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW))
cross
cross_ex
print(plus_sum);
h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred)
h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred)
h2o.performance(gbm, newdata = plusData)
h2o.predict(gbm, plusData)
pluspred$predict
h2o.table(plusData$W_4, pluspred$predict)
matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L"
matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
cross
h2o.table(plusData_ex$W_4, pluspred_ex$predict)
matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW))
cross_ex
plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex
plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex;
plusgbm_perf <- h2o.performance(gbm, newdata = plusData) plusgbm_AUC <- plusgbm_perf@metrics$AUC plusgbm_perf_ex <- h2o.performance(gbm_ex, newdata = plusData_ex) plusgbm_AUC_ex <- plusgbm_perf_ex@metrics$AUC plusgbm_AUC; plusgbm_AUC_ex
h2o.AUC(h2o.performance(gbm, newdata = plusData))
 h2o.auc(h2o.performance(gbm, newdata = plusData))
plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_AUC; plusgbm_AUC_ex
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train); dim(valid); dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex); dim(valid_ex); dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex))
h2o.auc(h2o.performance(m, newdata = test))
h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred)
h2o.accuracy(h2o.performance(m, newdata = test))
h2o.accuracy(h2o.predict(m, test))
h2o.accuracy(h2o.predict(m, test))
h2o.predict(m, test)
h2o.performance(m, test)
h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred)
h2o.table(test$W_4)
h2o.performance(m, newdata = test)
str(h2o.performance(m, newdata = test))
h2o.confusionMatrix(h2o.performance(m, newdata = test))
h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train); dim(valid); dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex); dim(valid_ex); dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,       stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData))
h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex))
h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) h2o.confusionMatrix(h2o.performance(m, newdata = test))
h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) h2o.confusionMatrix(h2o.performance(rf, newdata = test))
h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) h2o.confusionMatrix(h2o.performance(gbm, newdata = test))
h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) h2o.confusionMatrix(h2o.performance(m, newdata = plusData))
h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex))
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") #h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) h2o.confusionMatrix(h2o.performance(m, newdata = plusData)) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") #h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex)) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") #h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) h2o.confusionMatrix(h2o.performance(rf, newdata = plusData)) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") #h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex)) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") #h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData)) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") #h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
plusData <- read.table('./plus/married_46_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m, newdata = plusData)) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex)) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf, newdata = plusData)) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex)) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData)) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum); print("married_46_plus"); print(dim(plusData)[1]); print(plus_sum);
h2o.table(plusData$W_4, pluspred$predict)
matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW))
h2o.table(plusData_ex$W_4, pluspred_ex$predict) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex
matrix_ex
matrix$LL <- matrix[[1]] == 0 & matrix[[2]] == 0
matrix$LL
sum(matrix$LL)
matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L"
sum(matrix$LL)
matrix$LL
head(matrix$LL,10)
tail(matrix$LL,10)
tail(h2o.table(plusData$W_4, pluspred$predict), 10)
tail(pluspred$predict, 10)
tail(plusData$W_4, 10)
plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_AUC; plusgbm_AUC_ex
plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1102.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1102.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
library(h2o)
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('married_46.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train); dim(valid); dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex); dim(valid_ex); dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,       stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("married_46"); print(dim(h2oData)[1]); print(perf_sum);
head(m@model$variable_importances,10);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
# rm(list = ls()) # install.packages("h2o") #library(h2o) #library(stringr);library(dplyr) rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train); dim(valid); dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex); dim(valid_ex); dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,       stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum);
head(m@model$variable_importances,10);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
head(gbm@model$variable_importances,10);
gbm
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('./plus/full_data1102_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신')) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
train_ex
train
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m, newdata = plusData)) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex)) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf, newdata = plusData)) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex)) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData)) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum); ################## ################## ################# #("deep");head(m@model$variable_importances,10); #("rf");head(rf@model$variable_importances,10); #("gbm");head(gbm@model$variable_importances,10); #supplyNum <- read.csv('supply_num.csv', header = TRUE) #h2oData <- left_join(h2oData,supplyNum,by = "BLOCK_NM") #h2oData <- h2oData[, c(7,11,24:27,38:42,44)] # check the correlation between the winner's probablity and top N vairbale importance tmp_varimp = head(data.frame(h2o.varimp(gbm))) tmp_varimp tmp_pred = h2o.predict(gbm, plusData) tmp_pred # correlation  h2o.cor(tmp_pred$W, tmp_pred$A_47) h2o.cor(tmp_pred$W, tmp_pred$W_28) h2o.cor(tmp_pred$W, tmp_pred$W_29) h2o.cor(tmp_pred$W, tmp_pred$W_20) h2o.cor(tmp_pred$W, tmp_pred$W_38) # train$W_4,train$A_47 tmp_train = as.data.frame(train) setNames(aggregate(tmp_train$A_47, by = list(tmp_train$W_4), FUN = mean), c("Y", "X")) # t-test ########################################## #confusion Matrix h2o.table(plusData$W_4, pluspred$predict) matrix <- c(plusData$W_4, pluspred$predict) matrix$LL <- matrix[[1]] == "L" & matrix[[2]] == "L" matrix$LW <- matrix[[1]] == "L" & matrix[[2]] != "L" matrix$WL <- matrix[[1]] != "L" & matrix[[2]] == "L" matrix$WW <- matrix[[1]] != "L" & matrix[[2]] != "L" cross <- c(sum(matrix$LL), sum(matrix$LW), sum(matrix$WL), sum(matrix$WW)) h2o.table(plusData_ex$W_4, pluspred_ex$predict) matrix_ex <- c(plusData_ex$W_4, pluspred_ex$predict) matrix_ex$LL <- matrix_ex[[1]] == "L" & matrix_ex[[2]] == "L" matrix_ex$LW <- matrix_ex[[1]] == "L" & matrix_ex[[2]] != "L" matrix_ex$WL <- matrix_ex[[1]] != "L" & matrix_ex[[2]] == "L" matrix_ex$WW <- matrix_ex[[1]] != "L" & matrix_ex[[2]] != "L" cross_ex <- c(sum(matrix_ex$LL), sum(matrix_ex$LW), sum(matrix_ex$WL), sum(matrix_ex$WW)) #정확도=true/tot plusgbm_Accuracy <- (cross[1] + cross[4]) / dim(pluspred$predict)[1] plusgbm_Accuracy_ex <- (cross_ex[1] + cross_ex[4]) / dim(pluspred_ex$predict)[1] plusgbm_Accuracy; plusgbm_Accuracy_ex #hit raio=TruePositive=true pos/tot pos plusgbm_hit <- cross[4] / (cross[3] + cross[4]) plusgbm_hit_ex <- cross_ex[4] / (cross_ex[3] + cross_ex[4]) plusgbm_hit; plusgbm_hit_ex; #AUC plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_AUC; plusgbm_AUC_ex
print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
head(plusData)
plusData_ex
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('full_data1102.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신') ) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14","W_32","W_33","W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14","W_32", "W_33", "W_34")] write.table(highage_26, 'highage_26.csv') write.table(highage_36, 'highage_36.csv') write.table(highage_46, 'highage_46.csv') ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(disabled_26, 'disabled_26.csv') write.table(disabled_36, 'disabled_36.csv') write.table(disabled_46, 'disabled_46.csv') ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(married_46, 'married_46.csv') ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(general_26, 'general_26.csv') write.table(general_36, 'general_36.csv') write.table(general_26, 'general_46.csv')
#install.packages("stringr") #install.packages("dplyr") library(stringr) library(dplyr) full_data <- read.csv('./plus/full_data1102_plus.csv', encoding = 'EUC-KR') head(full_data) ## 우선/일반 나누기  full_data.priorty <- subset(full_data, W_14 %in% c('우고', '일고', 'N고', '우장', '일장', 'N장', '우신', '일신', 'N신')) full_data.general <- full_data %>% filter(!str_detect(W_14, "우")) ## REGNUM_BLOCK 필드 full_data.general$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.general$REGNUM_BLOCK) full_data.priorty$REGNUM_BLOCK <- gsub('호평', 'HO', full_data.priorty$REGNUM_BLOCK) ## BLOCK_NM 필드 full_data.general$BLOCK_NM <- gsub('호평', 'HO', full_data.general$BLOCK_NM) full_data.priorty$BLOCK_NM <- gsub('호평', 'HO', full_data.priorty$BLOCK_NM) ## W_3 필드 full_data.general$W_3 <- gsub('26형', '26F', full_data.general$W_3) full_data.general$W_3 <- gsub('36형', '36F', full_data.general$W_3) full_data.general$W_3 <- gsub('46형', '46F', full_data.general$W_3) full_data.priorty$W_3 <- gsub('26형', '26F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('36형', '36F', full_data.priorty$W_3) full_data.priorty$W_3 <- gsub('46형', '46F', full_data.priorty$W_3) ## W_4 필드 full_data.general$W_4 <- gsub('당첨', 'W', full_data.general$W_4) full_data.general$W_4 <- gsub('예비', 'L', full_data.general$W_4) full_data.general$W_4 <- gsub('낙첨', 'L', full_data.general$W_4) full_data.priorty$W_4 <- gsub('당첨', 'W', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('예비', 'L', full_data.priorty$W_4) full_data.priorty$W_4 <- gsub('낙첨', 'L', full_data.priorty$W_4) ## W_13 필드 full_data.general$W_13 <- gsub('1순위', '1st', full_data.general$W_13) full_data.general$W_13 <- gsub('2순위', '2nd', full_data.general$W_13) full_data.general$W_13 <- gsub('3순위', '3rd', full_data.general$W_13) full_data.priorty$W_13 <- gsub('1순위', '1st', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('2순위', '2nd', full_data.priorty$W_13) full_data.priorty$W_13 <- gsub('3순위', '3rd', full_data.priorty$W_13) ## W_14 필드 unique(full_data.general$W_14) unique(full_data.priorty$W_14) full_data.general$W_14 <- gsub('N장', 'ND', full_data.general$W_14) full_data.general$W_14 <- gsub('일장', 'GD', full_data.general$W_14) full_data.general$W_14 <- gsub('일일', 'GG', full_data.general$W_14) full_data.general$W_14 <- gsub('일고', 'GH', full_data.general$W_14) full_data.general$W_14 <- gsub('N일', 'NG', full_data.general$W_14) full_data.general$W_14 <- gsub('N고', 'NH', full_data.general$W_14) full_data.general$W_14 <- gsub('일중', 'GC', full_data.general$W_14) full_data.general$W_14 <- gsub('일노', 'GN', full_data.general$W_14) full_data.general$W_14 <- gsub('N한', 'NHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('일한', 'GHAN', full_data.general$W_14) full_data.general$W_14 <- gsub('N노', 'NN', full_data.general$W_14) full_data.general$W_14 <- gsub('N신', 'NM', full_data.general$W_14) full_data.general$W_14 <- gsub('N북', 'NBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('일북', 'GBOOK', full_data.general$W_14) full_data.general$W_14 <- gsub('N근', 'NGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('일신', 'GM', full_data.general$W_14) full_data.general$W_14 <- gsub('일근', 'GGEUN', full_data.general$W_14) full_data.general$W_14 <- gsub('N중', 'NC', full_data.general$W_14) full_data.priorty$W_14 <- gsub('우고', 'PH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일고', 'GH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N고', 'NH', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우장', 'PD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일장', 'GD', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N장', 'ND', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('우신', 'PM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('일신', 'GM', full_data.priorty$W_14) full_data.priorty$W_14 <- gsub('N신', 'NM', full_data.priorty$W_14) ## W_15 full_data.general$W_15 <- gsub('장애없음', 'N', full_data.general$W_15) full_data.general$W_15 <- gsub('6급', '6R', full_data.general$W_15) full_data.general$W_15 <- gsub('5급', '5R', full_data.general$W_15) full_data.general$W_15 <- gsub('4급', '4R', full_data.general$W_15) full_data.general$W_15 <- gsub('3급', '3R', full_data.general$W_15) full_data.general$W_15 <- gsub('2급', '2R', full_data.general$W_15) full_data.general$W_15 <- gsub('1급', '1R', full_data.general$W_15) full_data.priorty$W_15 <- gsub('장애없음', 'N', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('6급', '6R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('5급', '5R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('4급', '4R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('3급', '3R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('2급', '2R', full_data.priorty$W_15) full_data.priorty$W_15 <- gsub('1급', '1R', full_data.priorty$W_15) ## W_16 ## W_18 full_data.general$W_18 <- gsub('당해', 'RESI', full_data.general$W_18) full_data.general$W_18 <- gsub('타', 'N_RESI', full_data.general$W_18) full_data.priorty$W_18 <- gsub('당해', 'RESI', full_data.priorty$W_18) full_data.priorty$W_18 <- gsub('타', 'N_RESI', full_data.priorty$W_18) ## W_27 full_data.general$W_27 <- gsub("00년", "0", full_data.general$W_27) full_data.general$W_27 <- gsub("01년", "1", full_data.general$W_27) full_data.general$W_27 <- gsub("02년", "2", full_data.general$W_27) full_data.general$W_27 <- gsub("03년", "3", full_data.general$W_27) full_data.general$W_27 <- gsub("04년", "4", full_data.general$W_27) full_data.general$W_27 <- gsub("05년", "5", full_data.general$W_27) full_data.general$W_27 <- gsub("06년", "6", full_data.general$W_27) full_data.general$W_27 <- gsub("07년", "7", full_data.general$W_27) full_data.general$W_27 <- gsub("08년", "8", full_data.general$W_27) full_data.general$W_27 <- gsub("09년", "9", full_data.general$W_27) full_data.general$W_27 <- gsub("10년", "10", full_data.general$W_27) full_data.general$W_27 <- gsub("11년", "11", full_data.general$W_27) full_data.general$W_27 <- gsub("12년", "12", full_data.general$W_27) full_data.general$W_27 <- gsub("13년", "13", full_data.general$W_27) full_data.general$W_27 <- gsub("14년", "14", full_data.general$W_27) full_data.general$W_27 <- gsub("15년", "15", full_data.general$W_27) full_data.general$W_27 <- gsub("16년", "16", full_data.general$W_27) full_data.general$W_27 <- gsub("17년", "17", full_data.general$W_27) full_data.general$W_27 <- gsub("18년", "18", full_data.general$W_27) full_data.general$W_27 <- gsub("19년", "19", full_data.general$W_27) full_data.general$W_27 <- gsub("20년", "20", full_data.general$W_27) full_data.general$W_27 <- gsub("21년", "21", full_data.general$W_27) full_data.general$W_27 <- gsub("22년", "22", full_data.general$W_27) full_data.general$W_27 <- gsub("23년", "23", full_data.general$W_27) full_data.general$W_27 <- gsub("24년", "24", full_data.general$W_27) full_data.general$W_27 <- gsub("25년", "25", full_data.general$W_27) full_data.general$W_27 <- gsub("26년", "26", full_data.general$W_27) full_data.general$W_27 <- gsub("27년", "27", full_data.general$W_27) full_data.general$W_27 <- gsub("28년", "28", full_data.general$W_27) full_data.general$W_27 <- gsub("29년", "29", full_data.general$W_27) full_data.general$W_27 <- gsub("30년", "30", full_data.general$W_27) full_data.general$W_27 <- gsub("31년", "31", full_data.general$W_27) full_data.general$W_27 <- gsub("32년", "32", full_data.general$W_27) full_data.general$W_27 <- gsub("33년", "33", full_data.general$W_27) full_data.general$W_27 <- gsub("34년", "34", full_data.general$W_27) full_data.general$W_27 <- gsub("35년", "35", full_data.general$W_27) full_data.general$W_27 <- gsub("36년", "36", full_data.general$W_27) full_data.general$W_27 <- gsub("37년", "37", full_data.general$W_27) full_data.general$W_27 <- gsub("38년", "38", full_data.general$W_27) full_data.general$W_27 <- gsub("39년", "39", full_data.general$W_27) full_data.general$W_27 <- gsub("40년", "40", full_data.general$W_27) full_data.general$W_27 <- gsub("41년", "41", full_data.general$W_27) full_data.general$W_27 <- gsub("42년", "42", full_data.general$W_27) full_data.general$W_27 <- gsub("43년", "43", full_data.general$W_27) full_data.general$W_27 <- gsub("44년", "44", full_data.general$W_27) full_data.general$W_27 <- gsub("45년", "45", full_data.general$W_27) full_data.general$W_27 <- gsub("46년", "46", full_data.general$W_27) full_data.general$W_27 <- gsub("47년", "47", full_data.general$W_27) full_data.general$W_27 <- gsub("48년", "48", full_data.general$W_27) full_data.general$W_27 <- gsub("63년", "63", full_data.general$W_27) full_data.priorty$W_27 <- gsub("00년", "0", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("01년", "1", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("02년", "2", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("03년", "3", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("04년", "4", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("05년", "5", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("06년", "6", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("07년", "7", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("08년", "8", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("09년", "9", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("10년", "10", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("11년", "11", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("12년", "12", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("13년", "13", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("14년", "14", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("15년", "15", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("16년", "16", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("17년", "17", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("18년", "18", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("19년", "19", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("20년", "20", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("21년", "21", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("22년", "22", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("23년", "23", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("24년", "24", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("25년", "25", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("26년", "26", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("27년", "27", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("28년", "28", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("29년", "29", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("30년", "30", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("31년", "31", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("32년", "32", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("33년", "33", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("34년", "34", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("35년", "35", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("36년", "36", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("37년", "37", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("38년", "38", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("39년", "39", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("40년", "40", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("41년", "41", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("42년", "42", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("43년", "43", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("44년", "44", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("45년", "45", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("46년", "46", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("47년", "47", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("48년", "48", full_data.priorty$W_27) full_data.priorty$W_27 <- gsub("63년", "63", full_data.priorty$W_27) ## W_38 full_data.general$W_38 <- gsub("해당없음", "N", full_data.general$W_38) full_data.general$W_38 <- gsub("0년", "0", full_data.general$W_38) full_data.general$W_38 <- gsub("1년", "1", full_data.general$W_38) full_data.general$W_38 <- gsub("2년", "2", full_data.general$W_38) full_data.general$W_38 <- gsub("3년", "3", full_data.general$W_38) full_data.general$W_38 <- gsub("4년", "4", full_data.general$W_38) full_data.general$W_38 <- gsub("5년", "5", full_data.general$W_38) full_data.priorty$W_38 <- gsub("해당없음", "N", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("0년", "0", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("1년", "1", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("2년", "2", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("3년", "3", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("4년", "4", full_data.priorty$W_38) full_data.priorty$W_38 <- gsub("5년", "5", full_data.priorty$W_38) ## W_39  full_data.general$W_39 <- gsub('해당없음', 'N', full_data.general$W_39) full_data.general$W_39 <- gsub('1순위', '1st', full_data.general$W_39) full_data.general$W_39 <- gsub('2순위', '2nd', full_data.general$W_39) full_data.priorty$W_39 <- gsub('해당없음', 'N', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('1순위', '1st', full_data.priorty$W_39) full_data.priorty$W_39 <- gsub('2순위', '2nd', full_data.priorty$W_39) ## W_40 full_data.general$W_40 <- gsub('해당없음', 'N', full_data.general$W_40) full_data.general$W_40 <- gsub('당해', 'RESI', full_data.general$W_40) full_data.general$W_40 <- gsub('타', 'N_RESI', full_data.general$W_40) full_data.priorty$W_40 <- gsub('해당없음', 'N', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('당해', 'RESI', full_data.priorty$W_40) full_data.priorty$W_40 <- gsub('타', 'N_RESI', full_data.priorty$W_40) summary(full_data.priorty) summary(full_data.general) highage_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) highage_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PH' | W_14 == 'GH' | W_14 == 'NH')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 highage_26 <- highage_26[, !names(highage_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_36 <- highage_36[, !names(highage_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] highage_46 <- highage_46[, !names(highage_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 장애인 disabled_26 <- subset(full_data.priorty, W_3 == '26F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_36 <- subset(full_data.priorty, W_3 == '36F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) disabled_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PD' | W_14 == 'GD' | W_14 == 'ND')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 disabled_26 <- disabled_26[, !names(disabled_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_36 <- disabled_36[, !names(disabled_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] disabled_46 <- disabled_46[, !names(disabled_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 신혼부부 married_46 <- subset(full_data.priorty, W_3 == '46F' & (W_14 == 'PM' | W_14 == 'GM' | W_14 == 'NM')) # W_1, W_6, W_14, W_32, W_33, W_34 제거 married_46 <- married_46[, !names(married_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] ## 일반공급 general_26 <- full_data.general %>% filter(W_3 == "26F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_36 <- full_data.general %>% filter(W_3 == "36F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) general_46 <- full_data.general %>% filter(W_3 == "46F" & W_14 %in% c('ND', 'GD', 'GG', 'GH', 'NG', 'NH', 'GC', 'GN', 'NHAN', 'GHAN', 'NN', 'NM', 'NBOOK', 'GBOOK', 'NGEUN', 'GM', 'GGEUN', 'NC')) ## W_1, W_6, W_14, W_32, W_33, W_34 제거 general_26 <- general_26[, !names(general_26) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_36 <- general_36[, !names(general_36) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] general_46 <- general_46[, !names(general_46) %in% c("W_1", "W_6", "W_14", "W_32", "W_33", "W_34")] write.table(highage_26, './plus/highage_26_plus.csv') write.table(highage_36, './plus/highage_36_plus.csv') write.table(highage_46, './plus/highage_46_plus.csv') write.table(disabled_26, './plus/disabled_26_plus.csv') write.table(disabled_36, './plus/disabled_36_plus.csv') write.table(disabled_46, './plus/disabled_46_plus.csv') write.table(married_46, './plus/married_46_plus.csv') write.table(general_26, './plus/general_26_plus.csv') write.table(general_36, './plus/general_36_plus.csv') write.table(general_26, './plus/general_46_plus.csv')
library(h2o)
rm(list = ls()) localH2O <- h2o.init(max_mem_size = '1g') ## using a max 1GB of RAM h2o.removeAll() ## clean slate - just in case the cluster was already running #'highage_26.csv', 'highage_36.csv', 'highage_46.csv', 'disabled_26.csv', #'disabled_36.csv', 'disabled_46.csv', 'general_26.csv', 'general_36.csv', 'married_46.csv', #'married_46.csv' ## data 불러오기 h2oData <- read.table('general_36.csv', header = TRUE) head(h2oData) h2oData <- h2oData[, - c(1:4, 8)] head(h2oData) ## H2O DataFrame으로 변경 h2oData <- as.h2o(h2oData) ## data 분리(train/valid/test) splits <- h2o.splitFrame(h2oData, c(0.6, 0.2), seed = 1111) train <- h2o.assign(splits[[1]], "train.hex") # 60% valid <- h2o.assign(splits[[2]], "valid.hex") # 60% test <- h2o.assign(splits[[3]], "test.hex") # 60% dim(train); dim(valid); dim(test); #파생변수 제외 data: train,valid,test train_ex <- train[, c(1:22)] valid_ex <- valid[, c(1:22)] test_ex <- test[, c(1:22)] dim(train_ex); dim(valid_ex); dim(test_ex); ## 예측하고자 하는 변수지정 response = 'W_4' # 당첨/탈락 여부 필드 ## predictors 지정 predictors <- setdiff(names(train), response) predictors_ex <- setdiff(names(train_ex), response) #predictors;predictors_ex; ## 모델 생성(deeplearning) 및 예측 ############################################################################################# m <- h2o.deeplearning(     model_id = "dl_model",     training_frame = train,     validation_frame = valid, ## validation dataset: used for scoring and early stopping     x = predictors,     y = response,     #activation="Rectifier",  ## default     #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each     epochs = 1,     variable_importances = T ## not enabled by default ) ## 모델 확인 summary(m) m_ex <- h2o.deeplearning(       model_id = "dl_model_ex",       training_frame = train_ex,       validation_frame = valid_ex, ## validation dataset: used for scoring and early stopping       x = predictors_ex,       y = response,       #activation="Rectifier",  ## default       #hidden=c(200,200),       ## default: 2 hidden layers with 200 neurons each       epochs = 1,       variable_importances = T ## not enabled by default     ) ## 모델 확인 summary(m_ex) ## test 데이터를 통해 모델 정확도 예측 pred <- h2o.predict(m, test) pred_ex <- h2o.predict(m_ex, test_ex) #pred h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = test), thresholds = thred) m_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = test), thresholds = thred) m_hit <- h2o.tpr(h2o.performance(m, newdata = test), thresholds = thred) m_AUC <- h2o.auc(h2o.performance(m, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = test_ex), thresholds = thred) m_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = test_ex)) ################################################################################################################################# ## 모델 생성(randomforest) ###################################################################################################### rf <- h2o.randomForest(## h2o.randomForest function   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   model_id = "rf_covType", ## name the model in H2O                            ##   not required, but helps use Flow   ntrees = 200, ## use a maximum of 200 trees to create the                 ##  random forest model. The default is 50.                                      ##  I have increased it because I will let                                       ##  the early stopping criteria decide when                                      ##  the random forest is sufficiently accurate   stopping_rounds = 2, ## Stop fitting new trees when the 2-tree                                      ##  average is within 0.001 (default) of                                       ##  the prior two 2-tree averages.                                      ##  Can be thought of as a convergence setting   score_each_iteration = T, ## Predict against training and validation for                                      ##  each tree. Default will skip several.   seed = 1000000) ## Set the random seed so that this can be ##  reproduce summary(rf) rf_ex <- h2o.randomForest(## h2o.randomForest function       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)       x = predictors_ex, ## the predictor columns, by column index       y = response, ## the target index (what we are predicting)       model_id = "rf_covType_ex",       ntrees = 200,       stopping_rounds = 2,       score_each_iteration = T,       seed = 1000000) summary(rf_ex) rf_pred <- h2o.predict(object = rf, newdata = test) rf_pred_ex <- h2o.predict(object = rf_ex, newdata = test_ex) h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = test), thresholds = thred) rf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = test), thresholds = thred) rf_hit <- h2o.tpr(h2o.performance(rf, newdata = test), thresholds = thred) rf_AUC <- h2o.auc(h2o.performance(rf, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = test_ex), thresholds = thred) rf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = test_ex)) ################################################################################################################################ ## 모델생성(gbm) ############################################################################################################### checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex h2o.table(test$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = test), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = test), thresholds = thred) gbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = test)) h2o.table(test_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = test_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = test_ex), thresholds = thred) gbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = test_ex)) perf_sum <- data.frame(     EX.Accuracy = c(m_Accuracy_ex[[1]], rf_Accuracy_ex[[1]], gbm_Accuracy_ex[[1]]),     TEST.Accuracy = c(m_Accuracy[[1]], rf_Accuracy[[1]], gbm_Accuracy[[1]]),     EX.HIT = c(m_hit_ex[[1]], rf_hit_ex[[1]], gbm_hit_ex[[1]]),     TEST.HIT = c(m_hit[[1]], rf_hit[[1]], gbm_hit[[1]]),     EX.AUC = c(m_AUC_ex[[1]], rf_AUC_ex[[1]], gbm_AUC_ex[[1]]),     TEST.AUC = c(m_AUC[[1]], rf_AUC[[1]], gbm_AUC[[1]])) rownames(perf_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum);
head(h2oData)
valid_ex 
head(m@model$variable_importances,10);
head(rf@model$variable_importances,10);
head(gbm@model$variable_importances,10);
plusData <- read.table('./plus/general_36_plus.csv', header = TRUE) head(plusData) plusData <- plusData[, - c(1:4, 8)] head(plusData) ## H2O DataFrame으로 변경, 파생변수 제외 plusData <- as.h2o(plusData) plusData_ex <- plusData[, c(1:22)] str(plusData) #################### pluspred <- h2o.predict(m, plusData) pluspred_ex <- h2o.predict(m_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(m, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m, newdata = plusData)) plusm_Accuracy <- h2o.accuracy(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_hit <- h2o.tpr(h2o.performance(m, newdata = plusData), thresholds = thred) plusm_AUC <- h2o.auc(h2o.performance(m, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(m_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(m_ex, newdata = plusData_ex)) plusm_Accuracy_ex <- h2o.accuracy(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_hit_ex <- h2o.tpr(h2o.performance(m_ex, newdata = plusData_ex), thresholds = thred) plusm_AUC_ex <- h2o.auc(h2o.performance(m_ex, newdata = plusData_ex)) #####rf pluspred <- h2o.predict(rf, plusData) pluspred_ex <- h2o.predict(rf_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(rf, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf, newdata = plusData)) plusrf_Accuracy <- h2o.accuracy(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_hit <- h2o.tpr(h2o.performance(rf, newdata = plusData), thresholds = thred) plusrf_AUC <- h2o.auc(h2o.performance(rf, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(rf_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(rf_ex, newdata = plusData_ex)) plusrf_Accuracy_ex <- h2o.accuracy(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_hit_ex <- h2o.tpr(h2o.performance(rf_ex, newdata = plusData_ex), thresholds = thred) plusrf_AUC_ex <- h2o.auc(h2o.performance(rf_ex, newdata = plusData_ex)) #####gbm pluspred <- h2o.predict(gbm, plusData) pluspred_ex <- h2o.predict(gbm_ex, plusData_ex) h2o.table(plusData$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm, newdata = plusData), "f1") h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm, newdata = plusData)) plusgbm_Accuracy <- h2o.accuracy(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_hit <- h2o.tpr(h2o.performance(gbm, newdata = plusData), thresholds = thred) plusgbm_AUC <- h2o.auc(h2o.performance(gbm, newdata = plusData)) h2o.table(plusData_ex$W_4) thred = h2o.find_threshold_by_max_metric(h2o.performance(gbm_ex, newdata = plusData_ex), "f1") h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) #h2o.confusionMatrix(h2o.performance(gbm_ex, newdata = plusData_ex)) plusgbm_Accuracy_ex <- h2o.accuracy(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_hit_ex <- h2o.tpr(h2o.performance(gbm_ex, newdata = plusData_ex), thresholds = thred) plusgbm_AUC_ex <- h2o.auc(h2o.performance(gbm_ex, newdata = plusData_ex)) plus_sum <- data.frame(     EXPLUS.Accuracy = c(plusm_Accuracy_ex[[1]], plusrf_Accuracy_ex[[1]], plusgbm_Accuracy_ex[[1]]),     PLUS.Accuracy = c(plusm_Accuracy[[1]], plusrf_Accuracy[[1]], plusgbm_Accuracy[[1]]),     EXPLUS.HIT = c(plusm_hit_ex[[1]], plusrf_hit_ex[[1]], plusgbm_hit_ex[[1]]),     PLUS.HIT = c(plusm_hit[[1]], plusrf_hit[[1]], plusgbm_hit[[1]]),     EXPLUS.AUC = c(plusm_AUC_ex[[1]], plusrf_AUC_ex[[1]], plusgbm_AUC_ex[[1]]),     PLUS.AUC = c(plusm_AUC[[1]], plusrf_AUC[[1]], plusgbm_AUC[[1]])) rownames(plus_sum) <- c("deep", "rf", "gbm") print("general_36"); print(dim(h2oData)[1]); print(perf_sum); print("general_36_plus"); print(dim(plusData)[1]); print(plus_sum);
data.frame(h2o.varimp(gbm))
data.frame(h2o.varimp(rf))
checkpoint <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType1", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm <- h2o.gbm(   training_frame = train, ## the H2O frame for training   validation_frame = valid, ## the H2O frame for validation (not required)   x = predictors, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType1", ## name the model in H2O   variable_importances = T, ## not enabled by default   seed = 2000000) ## Set the random seed for reproducability summary(gbm) checkpoint <- h2o.gbm(   training_frame = train_ex, ## the H2O frame for training   validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 10000, # max_after_balance_size=5,    model_id = "gbm_covType2", ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability gbm_ex <- h2o.gbm(       training_frame = train_ex, ## the H2O frame for training       validation_frame = valid_ex, ## the H2O frame for validation (not required)   x = predictors_ex, ## the predictor columns, by column index   y = response, ## the target index (what we are predicting)   balance_classes = T,   ntrees = 20000, # max_after_balance_size=5,    checkpoint = checkpoint@model_id,   model_id = "gbm_covType2",   variable_importances = T, ## name the model in H2O   seed = 2000000) ## Set the random seed for reproducability #summary(gbm_ex) gbm_pred <- h2o.predict(object = gbm, newdata = test) gbm_pred_ex <- h2o.predict(object = gbm_ex, newdata = test_ex) #finalgbm_predictions;finalgbm_predictions_ex
